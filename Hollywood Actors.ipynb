{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hollywood Actors \n",
    "###  Can we predict if an actor won the Oscar based on the career article in Wikipedia?\n",
    "\n",
    "Shmuel Naaman "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "Based on your request I analyze the \"Holywood Actors\" articles in Wikipedia. I choose to use the list of actors that appears on 'Hollywood Walk of Fame motion picture stars'. This is not a complete list of actors but it represents significant stars in the Hollywood industry. The list includes around 900 actors 200 of them were nominated to Oscar and another 200 won an Oscar. \n",
    "\n",
    "I thought that building a model that classify actors that won the Oscar, nominated to Oscar and did not win the oscar will demonstrate some of my skills in data processing and modeling. \n",
    "\n",
    "Due to obviously limited time, I focus my efforts on efficient preprocessing that will enhance the signal. \n",
    " * I perform basic cleaning of the data \n",
    " * Used nltk sentence tokenizer as an input to create stem words.\n",
    " * Remove stop words\n",
    " * Perform word embodied as part of the deep neural network. \n",
    " * I choose to use an artificial recurrent neural network (RNN) architecture of the type Long short-term memory (LSTM). LSTM networks are well-suited to classifying, processing and making predictions based on time series data.\n",
    " \n",
    "These steps allow me to reduce the dimension of the problem, and work with relatively clean data. Which is particularly important for this data set which is quite small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wikipedia as wp\n",
    "import wikipediaapi\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import tensorflow as tf \n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils\n",
    "Optimally these functions would be in a separate file. However, since they include important steps of the analysis I decided to present them here with the rest of the analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data\n",
    " * Replace punctuation with tokens so we can use them in our model \n",
    " * Remove the word 'Oscar' from the article\n",
    " * Remove the words 'section' and 'Career' since they are related with the articale and not the actor\n",
    "There are many other preprocessing that worth considering here for example the work 'nomination' \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(text):\n",
    "    # Replace punctuation with tokens so we can use them in our model \n",
    "    # We remove the word 'Oscar' from the article\n",
    "    # We did remove the words 'section' and 'Career' since they are related with the articale and not the actor\n",
    "    # There are many other preprocessing that worth considering here for example the work 'nomination' \n",
    "    # We want to keep it simple and at the same time to demonstrate the analysis\n",
    "     \n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' <PERIOD> ')\n",
    "    text = text.replace(',', ' <COMMA> ')\n",
    "    text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
    "    text = text.replace(';', ' <SEMICOLON> ')\n",
    "    text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
    "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
    "    text = text.replace('(', ' <LEFT_PAREN> ')\n",
    "    text = text.replace(')', ' <RIGHT_PAREN> ')\n",
    "    text = text.replace('--', ' <HYPHENS> ')\n",
    "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
    "    text = text.replace('\\n', '')\n",
    "    text = text.replace(':', '')\n",
    "    text = text.replace('career', ' ')\n",
    "    text = text.replace('oscar', ' ')\n",
    "    text = text.replace('section', ' ')\n",
    "\n",
    "\n",
    "    return  text\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the words to roots\n",
    " Replace all words by the root words. \n",
    " * That will simplify the dataset by reducing the dimention of the data. \n",
    " * At the same time, considering the size of the data set, having all the variation of a key words as a single category might strength the signal.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Shmuel\n",
      "[nltk_data]     Naaman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Shmuel\n",
      "[nltk_data]     Naaman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Shmuel Naaman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     C:\\Users\\Shmuel Naaman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import nltk resources\n",
    "resources = [\"wordnet\", \"stopwords\", \"punkt\", \\\n",
    "             \"averaged_perceptron_tagger\", \"maxent_treebank_pos_tagger\"]\n",
    "\n",
    "for resource in resources:\n",
    "    try:\n",
    "        nltk.data.find(\"tokenizers/\" + resource)\n",
    "    except LookupError:\n",
    "        nltk.download(resource)\n",
    "\n",
    "# Create Lemmatizer object\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# Stem words\n",
    "def lemmatize_word(tagged_token):\n",
    "    \"\"\" Returns lemmatized word given its tag\"\"\"\n",
    "    root = []\n",
    "    for token in tagged_token:\n",
    "        tag = token[1][0]\n",
    "        word = token[0]\n",
    "        if tag.startswith('J'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.ADJ))\n",
    "        elif tag.startswith('V'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.VERB))\n",
    "        elif tag.startswith('N'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.NOUN))\n",
    "        elif tag.startswith('R'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.ADV))\n",
    "        else:          \n",
    "            root.append(word)\n",
    "    return root\n",
    "\n",
    "def lemmatize_doc(document):\n",
    "    \"\"\" Tags words then returns sentence with lemmatized words\"\"\"\n",
    "    lemmatized_list = []\n",
    "    tokenized_sent = sent_tokenize(document)\n",
    "    for sentence in tokenized_sent:\n",
    "        # Seperating sentences\n",
    "        tokenized_word = word_tokenize(sentence)\n",
    "        # Identify nouns, verbs, adjectives, and adverbs.\n",
    "        tagged_token = pos_tag(tokenized_word)\n",
    "        # Clasify to root word\n",
    "        lemmatized = lemmatize_word(tagged_token)\n",
    "        lemmatized_list.extend(lemmatized)\n",
    "    return \" \".join(lemmatized_list)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import list of Hollywood Actors names. \n",
    "Wikipedia: \"List of actors with Hollywood Walk of Fame motion picture stars\".\n",
    "\n",
    "I used the 'wikipedia' library which is awesome and save a lot of work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the html source\n",
    "html = wp.page(\"List_of_actors_with_Hollywood_Walk_of_Fame_motion_picture_stars\").html().encode(\"UTF-8\")\n",
    "df = pd.read_html(html)[1]\n",
    "\n",
    "# Replace the header with the first row\n",
    "new_header = df.iloc[0] \n",
    "df = df[1:]  \n",
    "df.columns = new_header \n",
    "\n",
    "# ading a column for the careere \n",
    "df['career']='a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 899 entries, 1 to 899\n",
      "Data columns (total 10 columns):\n",
      "Actor       899 non-null object\n",
      "nan         899 non-null object\n",
      "Born        899 non-null object\n",
      "Died        899 non-null object\n",
      "Age         899 non-null object\n",
      "Address     899 non-null object\n",
      "Inducted    899 non-null object\n",
      "At age      899 non-null object\n",
      "Oscar       899 non-null object\n",
      "career      899 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 70.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oscar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oscar</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nom</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Won</th>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>~</th>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0      Oscar\n",
       "Oscar       \n",
       "Nom      173\n",
       "Won      176\n",
       "~        550"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGLCAYAAACBaztdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKoxBQ5IkFeb/Azf5gsd54j/eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2cfcae8ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% pylab inline\n",
    "df.groupby([ 'Oscar'])[['Oscar']].count().plot(kind='bar').set_ylabel('Count')\n",
    "df.groupby(['Oscar' ])[['Oscar']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 1: The 'Nomination' (Nom) and 'Won' are balanced but many actors are not in either of these categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import the actors 'Career' article. \n",
    " * Here we use \"wikipediaapi\" library to extract the 'Career' section for each actor article that appears in the list.  \n",
    " * It is important to note here that the preprocessing is perform as we reading the data. Hopefully, that will save processing time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nltk sentance tokenizer. \n",
    "* tag words. \n",
    "* root on the original text. stanford nlp library. \n",
    "* stop words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting the Career for each actor and adding them to the dataframe\n",
    " \n",
    "all_text=str([])\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "stop_words = [word.replace(\"\\'\", \"\") for word in stop_words]\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia('en')\n",
    "\n",
    "for ind, actor_n in  enumerate(df.Actor):\n",
    "    # Uploading the actor article.\n",
    "    page_py = wiki_wiki.page(actor_n)\n",
    "    # Extracting the \"Career\" section and preprocessing the text.\n",
    "    example_sent = preprocess(lemmatize_doc(str(page_py.section_by_title('Career')))) \n",
    "    # Stop words\n",
    "    section_py = ' '.join([w for w in example_sent.split() if not w in stop_words])    \n",
    "    # Processed \"Career\" section saved into a \"bag of words\" for the encoding \n",
    "    all_text += section_py\n",
    "    \n",
    "    # Procesed \"Career\" section added to the dataframe\n",
    "    df['career'].iloc[ind] = section_py\n",
    "# \"bag of words\"\n",
    "words = all_text.split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words : 29701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[]<LEFT_PAREN>',\n",
       " '1',\n",
       " '<RIGHT_PAREN>',\n",
       " 'sub',\n",
       " '<LEFT_PAREN>',\n",
       " '3',\n",
       " '<RIGHT_PAREN>',\n",
       " 'lou',\n",
       " 'costello',\n",
       " 'hollywood',\n",
       " '<LEFT_PAREN>',\n",
       " '2',\n",
       " '<RIGHT_PAREN>',\n",
       " 'abbott',\n",
       " 'cross',\n",
       " 'path',\n",
       " 'lou',\n",
       " 'costello',\n",
       " 'early',\n",
       " '1930s',\n",
       " 'abbott',\n",
       " 'produce',\n",
       " 'perform',\n",
       " 'minsky',\n",
       " \"'s\",\n",
       " 'burlesque',\n",
       " 'show',\n",
       " 'costello',\n",
       " 'rise',\n",
       " 'comic']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del all_text\n",
    "print('Number of unique words :',len(set(words)))\n",
    "words[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_words =pd.DataFrame(words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels\n",
    "Using one hot encoding to labels categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = [  'Nom','won','non' ]\n",
    "labels =    pd.DataFrame(  columns=columns)\n",
    "labels[[ 'Nom','won','non']] =  pd.DataFrame(pd.get_dummies(df['Oscar']))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nom</th>\n",
       "      <th>won</th>\n",
       "      <th>non</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nom  won  non\n",
       "1    0    0    1\n",
       "2    0    0    1\n",
       "3    1    0    0\n",
       "4    0    0    1\n",
       "5    0    0    1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_words.to_csv('words.csv' ,index=False)\n",
    "#df.to_csv('holly_actr.csv' )\n",
    "#labels.to_csv('labels.csv' ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_words = pd.read_csv('words.csv') \n",
    "#words = df_words['0'].values.tolist()\n",
    "#df = pd.read_csv('holly_actr.csv') \n",
    "#labels = pd.read_csv('labels.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the words\n",
    "Each unique word in the 'bag of words' gets an integer. That will be used to encode the text in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    " \n",
    "\n",
    "career_ints = []\n",
    "for i, each in enumerate(df['career']):\n",
    "     \n",
    "    if (each !='none' and each !='a' and  each !='nan'):\n",
    "        career_ints.append([vocab_to_int[word] for word in each.split()])\n",
    "    else:\n",
    "        career_ints.append([0])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview for the career articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-length reviews: 429\n",
      "Maximum review length: 7139\n"
     ]
    }
   ],
   "source": [
    "review_lens = Counter([len(x) for x in career_ints])\n",
    "print(\"1-length reviews: {}\".format(review_lens[1]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that around half of the actors have no articles. That might be due to a different section name. In some cases, the 'early life' section is combined with the 'career'. This is something that can be solved. However, the data include enough articles to demonstrate the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>899.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>566.721913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>904.181918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>843.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7139.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count   899.000000\n",
       "mean    566.721913\n",
       "std     904.181918\n",
       "min       1.000000\n",
       "25%       1.000000\n",
       "50%     152.000000\n",
       "75%     843.500000\n",
       "max    7139.000000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGHCAYAAABxmBIgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJLWaYUWSJLXab78UsGrTn58IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d0246bea20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as pl\n",
    "#pd.DataFrame.from_dict(  review_lens ) \n",
    "review_le =  ([len(x) for x in career_ints])\n",
    "review_df = pd.DataFrame(review_le)\n",
    "\n",
    "review_df .hist(bins = 20) \n",
    "pl.xlabel('Number of words')\n",
    "pl.ylabel('Number of samples')\n",
    "pl.title('distribution of Number of words in articles')\n",
    "pd.DataFrame(review_df.describe())\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 2: 50% of the articles are shorter than 150 words. The average number of words in the articles is 566 words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles that have career section and the actor won or was nominated to Oscar: 214\n"
     ]
    }
   ],
   "source": [
    "samp = len(df[ (df['Oscar'] != '~') & (df['career'] != 'none') ])\n",
    "print(\"Number of articles that have career section and the actor won or was nominated to Oscar: {}\".format(samp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for the model\n",
    "Create an array of features that contains the data we'll pass to the network. The data come from 'career_ints', since we want to feed integers to the network. Each row is 300 words long. The shorter rows are than pads with 0s. For the long rows, only the first 300 words are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_len = 300\n",
    "features = np.zeros((len(career_ints), seq_len), dtype=int)\n",
    "for i, row in enumerate(career_ints):\n",
    "    features[i, -len(row):] = np.array(row)[:seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    3,    61,     4, ...,     2,   341,     6],\n",
       "       [    0,     0,     0, ...,     0,     0,     0],\n",
       "       [    3,    61,     4, ..., 17307,     1,  3288],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     0,     0,     0],\n",
       "       [    0,     0,     0, ...,     3,    19,     4],\n",
       "       [    0,     0,     0, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(719, 300) \n",
      "Validation set: \t(90, 300) \n",
      "Test set: \t\t(90, 300) \n",
      "Test set: \t\t(90, 3) \n",
      "Validation set: \t(90, 3) \n",
      "Train set: \t\t(719, 3)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "split_idx = int(len(features)*0.8)\n",
    "train_x, val_x = features[:split_idx], features[split_idx:]\n",
    "train_y, val_y = labels.values[:split_idx ], labels.values[split_idx: ]\n",
    "\n",
    "test_idx = int(len(val_x)*0.5)\n",
    "val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
    "val_y, test_y = val_y[:test_idx], val_y[test_idx:]\n",
    "\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_y.shape),\n",
    "     \"\\nValidation set: \\t{}\".format(val_y.shape),\n",
    "     \"\\nTrain set: \\t\\t{}\".format(train_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the graph\n",
    "\n",
    "### Hyperparameters Defining.\n",
    "\n",
    "* `lstm_size`: Number of units in the hidden layers in the LSTM cells. \n",
    "* `lstm_layers`: Number of LSTM layers in the network.\n",
    "* `batch_size`: The number of articles to feed the network in one training pass.  \n",
    "* `learning_rate`: Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "lstm_size = 256\n",
    "lstm_layers = 1\n",
    "batch_size = 90\n",
    "learning_rate = 0.001\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the network itself, we'll be passing in 300 words long vectors. Each batch will be batch_size vectors. We'll also be using dropout on the LSTM layer, so we'll make a placeholder for the keep probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_words = len(vocab_to_int) + 1 # Adding 1 because we use 0's for padding, dictionary started at 1\n",
    "\n",
    "# Create the graph object\n",
    "graph = tf.Graph()\n",
    "# Add nodes to the graph\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "    labels_ = tf.placeholder(tf.int32, [None, None], name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "Now we'll add an embedding layer. We need to do this because it is inefficient to one-hot encode our classes here. Instead of one-hot encoding, we can have an embedding layer and use that layer as a lookup table. It is also possible to train an embedding layer using word2vec, then load it here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size of the embedding vectors (number of units in the embedding layer)\n",
    "embed_size = 300 \n",
    "\n",
    "with graph.as_default():\n",
    "    embedding = tf.Variable(tf.random_uniform((n_words, embed_size), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM cell\n",
    "\n",
    " \n",
    "Next, we'll create our LSTM cells to use in the recurrent network ([TensorFlow documentation](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn)). \n",
    "\n",
    "To create a basic LSTM cell for the graph, we'll   use `tf.contrib.rnn.BasicLSTMCell`.\n",
    "\n",
    "```\n",
    "tf.contrib.rnn.BasicLSTMCell(num_units, forget_bias=1.0, input_size=None, state_is_tuple=True, activation=<function tanh at 0x109f1ef28>)\n",
    "```\n",
    "\n",
    "BasicLSTMCell   takes a parameter `num_units`, the number of units in the cell (`lstm_size`).  \n",
    "\n",
    " \n",
    "\n",
    "Next, we add dropout to the cell with `tf.contrib.rnn.DropoutWrapper`. This just wraps the cell in another cell, but with dropout added to the inputs and/or outputs. It's a really convenient way to make the network better with almost no effort! \n",
    "\n",
    "\n",
    "The network will have better performance with more layers. Adding more layers allows the network to learn complex relationships. A simple way to create multiple layers of LSTM cells with `tf.contrib.rnn.MultiRNNCell`:\n",
    "\n",
    "```\n",
    "cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "```\n",
    "\n",
    "Here, `[drop] * lstm_layers` creates a list of cells (`drop`) that is `lstm_layers` long. The `MultiRNNCell` wrapper builds this into multiple layers of RNN cells, one for each cell in the list.\n",
    "\n",
    "So the final cell we're using in the network is actually multiple  LSTM cells with dropout. But it all works the same from an architectural viewpoint, just a more complicated graph in the cell.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    \n",
    "    # Dropout to the cell\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN forward pass\n",
    "Now we need to actually run the data through the RNN nodes. We use tf.nn.dynamic_rnn to do this. We pass in the RNN cell you created (our multiple layered LSTM cell for instance), and the inputs to the network.\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state)\n",
    "Above I created an initial state, initial_state, to pass to the RNN. This is the cell state that is passed between the hidden layers in successive time steps. tf.nn.dynamic_rnn takes care of most of the work for us. We pass in our cell and the input to the cell, then it does the unrolling and everything else for us. It returns outputs for each time step and the final_state of the hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, embed,\n",
    "                                             initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "#### Training Cost\n",
    "We only care about the final output, we'll be using that as our prediction. So we need to grab the last output with `outputs[:, -1]`, the calculate the cost from that and `labels_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    predictions = tf.contrib.layers.fully_connected(outputs[:, -1], NUM_CLASSES, \n",
    "                                                    activation_fn=tf.sigmoid)\n",
    "    cost = tf.losses.mean_squared_error(labels_, predictions)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation accuracy\n",
    "Here we   calculate the accuracy which I'll use in the validation pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching\n",
    "This function returning batches from our data. First it removes data such that we only have full batches. Then it iterates through the x and y arrays and returns slices out of those arrays with size [batch_size]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=90):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below is the training code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5 Iteration: 5 Train loss: 0.213\n",
      "Epoch: 1/5 Iteration: 10 Train loss: 0.187\n",
      "Epoch: 2/5 Iteration: 15 Train loss: 0.146\n",
      "Epoch: 2/5 Iteration: 20 Train loss: 0.157\n",
      "Epoch: 3/5 Iteration: 25 Train loss: 0.163\n",
      "Val acc: 0.719\n",
      "Epoch: 4/5 Iteration: 30 Train loss: 0.139\n",
      "Epoch: 4/5 Iteration: 35 Train loss: 0.165\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    " \n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, :],\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state}\n",
    "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
    "            \n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "\n",
    "            if iteration%25==0:\n",
    "                val_acc = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                for x, y in get_batches(val_x, val_y, batch_size):\n",
    "                    feed = {inputs_: x,\n",
    "                            labels_: y[:,:],\n",
    "                            keep_prob: 1,\n",
    "                            initial_state: val_state}\n",
    "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "             \n",
    "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "            iteration +=1\n",
    "    saver.save(sess, \"checkpoints/sentiment.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\sentiment.ckpt\n",
      "Test accuracy: 0.704\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    for ii, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
    "        feed = {inputs_: x,\n",
    "                labels_: y[:, :],\n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state}\n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single case\n",
    "We can enter a actor name and the model will categorize whather it win was nominated or none. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actor_n='Javier Bardem'\n",
    "page_py = wiki_wiki.page(actor_n)\n",
    "# Extracting the \"Career\" section and preprocessing the text.\n",
    "example_sent = preprocess(lemmatize_doc(str(page_py.section_by_title('Career')))) \n",
    "# Stop words\n",
    "section_py = ' '.join([w for w in example_sent.split() if not w in stop_words])    \n",
    "\n",
    "each = section_py\n",
    "\n",
    "career_ints = []\n",
    "\n",
    "if (each !='none' and each !='a' and  each !='nan'):\n",
    "    career_ints.append([vocab_to_int[word] for word in each.split()])\n",
    "else:\n",
    "    career_ints.append([0])\n",
    "\n",
    "seq_len = 300\n",
    "features = np.zeros((len(career_ints), seq_len), dtype=int)\n",
    "row = career_ints\n",
    "\n",
    "for i, row in enumerate(career_ints):\n",
    "    features[i, -len(row):] = np.array(row)[:seq_len]\n",
    "\n",
    "samp = features[0,:].reshape(1,300)\n",
    "test_x1=test_x\n",
    "test_x1[0]=samp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\sentiment.ckpt\n",
      "Javier Bardem Won\n"
     ]
    }
   ],
   "source": [
    " \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    #for ii, (x, y) in enumerate(get_batches(samp_x, samp_y  , batch_size), 1):\n",
    " \n",
    "    feed = {inputs_: test_x1, \n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state}\n",
    "    pred1  = sess.run([predictions ], feed_dict=feed)\n",
    " \n",
    "    print(actor_n,['Nom','Won','Nan'][np.where(pred1[0][0]==np.max(pred1[0][0]))[0][0]] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def actor_oscar(actor_n):\n",
    "     \n",
    "    page_py = wiki_wiki.page(actor_n)\n",
    "    # Extracting the \"Career\" section and preprocessing the text.\n",
    "    example_sent = preprocess(lemmatize_doc(str(page_py.section_by_title('Career')))) \n",
    "    # Stop words\n",
    "    section_py = ' '.join([w for w in example_sent.split() if not w in stop_words])    \n",
    "\n",
    "    each = section_py\n",
    "\n",
    "    career_ints = []\n",
    "\n",
    "    if (each !='none' and each !='a' and  each !='nan'):\n",
    "        career_ints.append([vocab_to_int[word] for word in each.split()])\n",
    "    else:\n",
    "        career_ints.append([0])\n",
    "\n",
    "    seq_len = 300\n",
    "    features = np.zeros((len(career_ints), seq_len), dtype=int)\n",
    "    row = career_ints\n",
    "\n",
    "    for i, row in enumerate(career_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_len]\n",
    "\n",
    "    samp = features[0,:].reshape(1,300)\n",
    "    test_x1=test_x\n",
    "    test_x1[0]=samp \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "        test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "        #for ii, (x, y) in enumerate(get_batches(samp_x, samp_y  , batch_size), 1):\n",
    "\n",
    "        feed = {inputs_: test_x1, \n",
    "                    keep_prob: 1,\n",
    "                    initial_state: test_state}\n",
    "        pred1  = sess.run([predictions ], feed_dict=feed)\n",
    "\n",
    "    print(actor_n,['Nom','Won','Nan'][np.where(pred1[0][0]==np.max(pred1[0][0]))[0][0]] ) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\sentiment.ckpt\n"
     ]
    }
   ],
   "source": [
    "actor_oscar('Javier Bardem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reflection\n",
    "\n",
    "The model performs better than I expected, I find that somehow suspicious! I would like to find out what are the main reasons for that high performance.  \n",
    "\n",
    "Optional sources that should be examined:  \n",
    " * The length of the article. I suspect that Oscar nomination and Oscar holders will have longer text. \n",
    " * The word 'nomination' (or other words) with all its variation might bias the text. \n",
    " * The metric that we choose together with the unbalanced labels might bias the results. The metric considers the performance of the model for the 3 categories. Perhaps a more focus metric will show a different result. \n",
    " * Comparing the performance to some baseline. For example, What will be the accuracy if all prediction is \"not nominated and not won\". \n",
    " \n",
    "### Improvements \n",
    " * The preprocessing was quite basic, there are other approaches for data preprocessing that can be used. \n",
    " * Larger data set will allow us to use the actual words instead of the roots. \n",
    " * Not all the possible articles where uploaded. Better data collection will increase the information in the dataset. \n",
    " * The model was quite simple, we can increase the number of hidden layers and the number of neurons. We can use other models.  \n",
    " * The cleaning of the data can be more sophisticated. We can easily remove words with very high or very low frequency. Some of the words in the articles are related to numbering the sections that can be removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference \n",
    "#### # Extracting the names of actors and the oscar nomination :  https://qxf2.com/blog/web-scraping-using-python/\n",
    "\n",
    "#### # Extracting the career : https://pypi.org/project/Wikipedia-API/0.2.0/\n",
    "#### # Model : https://github.com/udacity/deep-learning/blob/master/sentiment-rnn/Sentiment_RNN_Solution.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras_1]",
   "language": "python",
   "name": "conda-env-keras_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
